import requests
from langchain_core.output_parsers import PydanticOutputParser
from langchain.prompts import PromptTemplate
import json
from hwpx_report.jbnu_pydantic_file import Title  # ìœ„ì—ì„œ ë§Œë“  ëª¨ë¸
import re


from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage

# ChatOpenAI ì´ˆê¸°í™”
llm = ChatOpenAI(
    base_url="",
    api_key="not-needed",
    model="Qwen3-14B",
    max_tokens=5000,
    streaming=False  # ìš”ì²­ì— ë”°ë¼ Trueë¡œë„ ê°€ëŠ¥
)

def generate_response(prompt: str, system_message: str = "") -> str:
    """
    LangChainì˜ ChatOpenAI ê°ì²´ë¥¼ ì‚¬ìš©í•´ í”„ë¡¬í”„íŠ¸ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    """
    try:
        messages = []

        if system_message:
            messages.append(SystemMessage(content=system_message))
        messages.append(HumanMessage(content=prompt))

        response = llm.invoke(messages)
        return response.content

    except Exception as e:
        return f"[ì—ëŸ¬ ë°œìƒ] {str(e)}"


json_analysis_for_hwp_parser = PydanticOutputParser(pydantic_object=Title)

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
json_analysis_for_hwp_prompt = PromptTemplate(
    template="""
    You are an AI that structures Korean-language reports. Read the full free-form report content provided below and convert it into detailed JSON format **verbatim, without summarizing or paraphrasing**.

    Keep all original details **exactly as written**, including numbers, statistics, and descriptions.

    Tables must be preserved exactly as-is under the "table" field. All values must be strings, even if they are numbers (e.g., "652282").

    Each main point must include a 'sub_title'.  
    If the original content does not provide one, **generate a relevant Korean sub_title from the full context**. Never leave 'sub_title' empty.

    ---

    ğŸ“¸ **Image Caption Handling Rule**

    If a line like ![í…ìŠ¤íŠ¸] or [í…ìŠ¤íŠ¸] appears within a content block, treat it as an image.

    - Extract the actual text inside the brackets as the caption (e.g., if ![ì›ì¸ë¶„ì„ë„], use "caption": "ì›ì¸ë¶„ì„ë„").
    - Do **not** use a generic word like "ì„¤ëª…".  
    - Then create an image object like this:

    json
        {{
            "caption": "í…ìŠ¤íŠ¸",
            "filename": "í…ìŠ¤íŠ¸.png",
            "type": "image"
        }}

    Insert the image object inside the 'images' field of the corresponding main point.

    â—Important: Output must be valid JSON only.

    ë³´ê³ ì„œ ë‚´ìš©:
    {content}

    JSON ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ:
    {format_instructions} 
    """,
        input_variables=["content"],
        partial_variables={
            "format_instructions": json_analysis_for_hwp_parser.get_format_instructions()
        },
    )


def extract_json_block(text: str) -> str:
    """
    LLM ì‘ë‹µì—ì„œ ê°€ì¥ ë¨¼ì € ë‚˜ì˜¤ëŠ” JSON ë¸”ë¡ë§Œ ì¶”ì¶œ
    """
    match = re.search(r"\{[\s\S]*\}", text)
    if match:
        return match.group()
    else:
        raise ValueError("JSON ë¸”ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

def generate_structured_report(content: str, output_path: str = "test_qwen3.json") -> dict:
    print("jsonìƒì„± ì‹œì‘")
    formatted_prompt = json_analysis_for_hwp_prompt.format(content=content)
    response = generate_response(prompt=formatted_prompt)

    print("=== LLM ì‘ë‹µ ì›ë¬¸ ===")
    print(response)
    print("====================")
    try:
        response_json_str = extract_json_block(response)
        parsed = json_analysis_for_hwp_parser.parse(response)

        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(parsed.model_dump(), f, ensure_ascii=False, indent=2)
        print("âœ… êµ¬ì¡°í™”ëœ JSON ì €ì¥ ì™„ë£Œ")

        return parsed.model_dump()
    except Exception as e:
        raise RuntimeError(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")